{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnvev5G4giqV"
      },
      "source": [
        "## MMDetection Model & WaterDataset Down"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/open-mmlab/mmsegmentation.git\n"
      ],
      "metadata": {
        "id": "HsNaOGlL00wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-6G8LoEDzcL"
      },
      "outputs": [],
      "source": [
        "# https://mmcv.readthedocs.io/en/latest/get_started/installation.html 설치 과정 참조.  \n",
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/index.html\n",
        "\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "!cd mmdetection; python setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D37np1MTS9XV"
      },
      "outputs": [],
      "source": [
        "# 런타임->런타임 다시 시작 후 아래 수행. \n",
        "from mmdet.apis import init_detector, inference_detector\n",
        "import mmcv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UT7659vvTJsx"
      },
      "outputs": [],
      "source": [
        "# Dataset down\n",
        "!curl -L \"https://app.roboflow.com/ds/5Y5O3sr8no?key=nsY9XUSK6Z\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iUXD66bNTJp_"
      },
      "outputs": [],
      "source": [
        "# pretrained weight 모델을 다운로드 받기 위해서 mmdetection/checkpoints 디렉토리를 만듬. \n",
        "!cd mmdetection; mkdir checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naLayCo0TJkJ"
      },
      "outputs": [],
      "source": [
        "# mask_rcnn_r101_fpn_1x_coco_20200204 pretrain model down\n",
        "!wget -O /content/mmdetection/checkpoints/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth http://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r101_fpn_1x_coco/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLDwaF5Bgiqc"
      },
      "source": [
        "## Config 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnc2K0ehTJhA"
      },
      "outputs": [],
      "source": [
        "#train model 저장할 checkpoint 파일 만들기\n",
        "!ls -lia /content/mmdetection/checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YgXbHazeTJcP"
      },
      "outputs": [],
      "source": [
        "# config 파일을 설정하고, 다운로드 받은 pretrained 모델을 checkpoint로 설정. \n",
        "config_file = '/content/mmdetection/configs/mask_rcnn/mask_rcnn_r101_fpn_1x_coco.py'\n",
        "checkpoint_file = '/content/mmdetection/checkpoints/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yC4M2gFgTJKo"
      },
      "outputs": [],
      "source": [
        "from mmdet.datasets.builder import DATASETS\n",
        "from mmdet.datasets.coco import CocoDataset\n",
        "\n",
        "@DATASETS.register_module(force=True)\n",
        "class WaterDataset(CocoDataset):\n",
        "  CLASSES = ('water','shade','smudge','water')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0T_q-ctQcBD5"
      },
      "outputs": [],
      "source": [
        "from mmcv import Config\n",
        "\n",
        "cfg = Config.fromfile(config_file)\n",
        "print(cfg.pretty_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DVzN-1Pgiqf"
      },
      "source": [
        "### Config 세부 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0zX4KxE_cDrH"
      },
      "outputs": [],
      "source": [
        "from mmdet.apis import set_random_seed\n",
        "\n",
        "# dataset에 대한 환경 파라미터 수정. \n",
        "cfg.dataset_type = 'WaterDataset'\n",
        "cfg.data_root = '/content/water/'\n",
        "\n",
        "# train, val, test dataset에 대한 type, data_root, ann_file, img_prefix 환경 파라미터 수정. \n",
        "cfg.data.train.type = 'WaterDataset'\n",
        "cfg.data.train.data_root = '/content/water/'\n",
        "cfg.data.train.ann_file = 'train.json'\n",
        "cfg.data.train.img_prefix = 'train'\n",
        "\n",
        "\n",
        "cfg.data.val.type = 'WaterDataset'\n",
        "cfg.data.val.data_root = '/content/water/'\n",
        "cfg.data.val.ann_file = 'val.json'\n",
        "cfg.data.val.img_prefix = 'val'\n",
        "\n",
        "\n",
        "cfg.data.test.type = 'WaterDataset'\n",
        "cfg.data.test.data_root = '/content/water/'\n",
        "cfg.data.test.ann_file = 'test.json'\n",
        "cfg.data.test.img_prefix = 'test'\n",
        "\n",
        "\n",
        "# class의 갯수를 pascal voc로 설정.  수정. \n",
        "cfg.model.roi_head.bbox_head.num_classes = 4\n",
        "cfg.model.roi_head.mask_head.num_classes = 4\n",
        "\n",
        "# pretrained 모델\n",
        "cfg.load_from = '/content/mmdetection/checkpoints/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth'\n",
        "\n",
        "# 학습 weight 파일로 로그를 저장하기 위한 디렉토리 설정. \n",
        "cfg.work_dir = './tutorial_exps'\n",
        "\n",
        "# 학습율 변경 환경 파라미터 설정. \n",
        "cfg.optimizer.lr = 0.02 / 10\n",
        "cfg.lr_config.warmup = None\n",
        "cfg.log_config.interval = 10\n",
        "\n",
        "# CocoDataset의 경우 metric을 bbox로 설정해야 함.(mAP아님. bbox로 설정하면 mAP를 iou threshold를 0.5 ~ 0.95까지 변경하면서 측정)\n",
        "cfg.evaluation.metric = ['bbox', 'segm']\n",
        "cfg.evaluation.interval = 150\n",
        "cfg.checkpoint_config.interval = 12\n",
        "cfg.runner.max_epochs = 150\n",
        "\n",
        "# 두번 config를 로드하면 lr_config의 policy가 사라지는 오류로 인하여 설정. \n",
        "cfg.lr_config.policy='step'\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(0, 1)\n",
        "cfg.auto_scale_lr. base_batch_size = 64\n",
        "# 'cuda' 사용\n",
        "cfg.device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AW0fs6oheSuv"
      },
      "outputs": [],
      "source": [
        "print(cfg.pretty_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z80yx-e7eVJU"
      },
      "outputs": [],
      "source": [
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "\n",
        "# train용 Dataset 생성. \n",
        "datasets = [build_dataset(cfg.data.train)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPIKhizxfffB"
      },
      "outputs": [],
      "source": [
        "model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "print(model.CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxneZ25vgiqh"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npAce8puftps"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "import time\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "# epochs는 config의 runner 파라미터로 지정됨. 기본 12회 \n",
        "start_time = time.time()\n",
        "train_detector(model, datasets, cfg, distributed=False, validate=True)\n",
        "print('time: ', time.time() - start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEhM5NYChXST"
      },
      "outputs": [],
      "source": [
        "# 배치사이즈 늘려서 트레인중\n",
        "from mmdet.apis import show_result_pyplot\n",
        "\n",
        "checkpoint_file = '/content/tutorial_exps/epoch_120.pth'\n",
        "\n",
        "# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n",
        "model_ckpt = init_detector(cfg, checkpoint_file, device='cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sczrUBaHf1BL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "labels_to_names_seq =  {1: 'shade', 2: 'smudge', 3:'water'}\n",
        "  \n",
        "colors = list(\n",
        "    [[0, 255, 0],\n",
        "     [0, 0, 255],\n",
        "     [255, 0, 0],\n",
        "     [0, 255, 255],\n",
        "     [255, 255, 0],\n",
        "     [255, 0, 255],\n",
        "     [80, 70, 180],\n",
        "     [250, 80, 190],\n",
        "     [245, 145, 50],\n",
        "     [70, 150, 250]] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM3NMvwHgiqi"
      },
      "source": [
        "### video 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ANaU7etZhM8M"
      },
      "outputs": [],
      "source": [
        "# model과 원본 이미지 array, filtering할 기준 class confidence score를 인자로 가지는 inference 시각화용 함수 생성. \n",
        "# 이미 inference 시 mask boolean값이 들어오므로 mask_threshold 값을 필요하지 않음. \n",
        "def get_detected_img(model, img_array,  score_threshold=0.3, is_print=True):\n",
        "  # 인자로 들어온 image_array를 복사. \n",
        "  draw_img = img_array.copy()\n",
        "  bbox_color=(0, 255, 0)\n",
        "  text_color=(0, 0, 255)\n",
        "\n",
        "  # model과 image array를 입력 인자로 inference detection 수행하고 결과를 results로 받음. \n",
        "  # results는 80개의 2차원 array(shape=(오브젝트갯수, 5))를 가지는 list. \n",
        "  results = inference_detector(model, img_array)\n",
        "  bbox_results = results[0]\n",
        "  seg_results = results[1]\n",
        "\n",
        "  # 80개의 array원소를 가지는 results 리스트를 loop를 돌면서 개별 2차원 array들을 추출하고 이를 기반으로 이미지 시각화 \n",
        "  # results 리스트의 위치 index가 바로 COCO 매핑된 Class id. 여기서는 result_ind가 class id\n",
        "  # 개별 2차원 array에 오브젝트별 좌표와 class confidence score 값을 가짐. \n",
        "  for result_ind, bbox_result in enumerate(bbox_results):\n",
        "    # 개별 2차원 array의 row size가 0 이면 해당 Class id로 값이 없으므로 다음 loop로 진행. \n",
        "    if len(bbox_result) == 0:\n",
        "      continue\n",
        "    \n",
        "    mask_array_list = seg_results[result_ind]\n",
        "    \n",
        "    # 해당 클래스 별로 Detect된 여러개의 오브젝트 정보가 2차원 array에 담겨 있으며, 이 2차원 array를 row수만큼 iteration해서 개별 오브젝트의 좌표값 추출. \n",
        "    for i in range(len(bbox_result)):\n",
        "      # 좌상단, 우하단 좌표 추출. \n",
        "      if bbox_result[i, 4] > score_threshold:\n",
        "        left = int(bbox_result[i, 0])\n",
        "        top = int(bbox_result[i, 1])\n",
        "        right = int(bbox_result[i, 2])\n",
        "        bottom = int(bbox_result[i, 3])\n",
        "        caption = \"{}: {:.4f}\".format(labels_to_names_seq[result_ind], bbox_result[i, 4])\n",
        "        cv2.rectangle(draw_img, (left, top), (right, bottom), color=bbox_color, thickness=2)\n",
        "        cv2.putText(draw_img, caption, (int(left), int(top - 7)), cv2.FONT_HERSHEY_SIMPLEX, 0.37, text_color, 1)\n",
        "        # masking 시각화 적용. class_mask_array는 image 크기 shape의  True/False값을 가지는 2차원 array\n",
        "        class_mask_array = mask_array_list[i]\n",
        "        # 원본 image array에서 mask가 True인 영역만 별도 추출. \n",
        "        masked_roi = draw_img[class_mask_array]\n",
        "        #color를 임의 지정\n",
        "        #color_index = np.random.randint(0, len(colors)-1)\n",
        "        \n",
        "        # color를 class별로 지정\n",
        "        color_index = result_ind % len(colors)\n",
        "        color = colors[color_index]\n",
        "        # apply_mask()함수를 적용시 수행 시간이 상대적으로 오래 걸림. \n",
        "        #draw_img = apply_mask(draw_img, class_mask_array, color, alpha=0.4)\n",
        "        # 원본 이미지의 masking 될 영역에 mask를 특정 투명 컬러로 적용\n",
        "        draw_img[class_mask_array] = ([0.3*color[0], 0.3*color[1], 0.3*color[2]] + 0.6 * masked_roi).astype(np.uint8)\n",
        "        if is_print:\n",
        "          print(caption)\n",
        "  \n",
        "  return draw_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5Ypf2z2ihPwk"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def do_detected_video(model, input_path, output_path, score_threshold, do_print=True):\n",
        "    \n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size) \n",
        "\n",
        "    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    print('총 Frame 갯수:', frame_cnt)\n",
        "    btime = time.time()\n",
        "    while True:\n",
        "        hasFrame, img_frame = cap.read()\n",
        "        if not hasFrame:\n",
        "            print('더 이상 처리할 frame이 없습니다.')\n",
        "            break\n",
        "        stime = time.time()\n",
        "        img_frame = get_detected_img(model, img_frame,  score_threshold=score_threshold,is_print=False)\n",
        "        if do_print:\n",
        "          print('frame별 detection 수행 시간:', round(time.time() - stime, 4))\n",
        "        vid_writer.write(img_frame)\n",
        "    # end of while loop\n",
        "\n",
        "    vid_writer.release()\n",
        "    cap.release()\n",
        "\n",
        "    print('최종 detection 완료 수행 시간:', round(time.time() - btime, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkhZip7egiqj"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKwoK8NEjhpe"
      },
      "outputs": [],
      "source": [
        "do_detected_video(model_ckpt, '/content/mp4/floor_water03.mp4', '/content/mp4/floor_water_out_01_epochs_150_batch_64_lr_0002.mp4', score_threshold=0.6, do_print=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5xYwP1hj_e4"
      },
      "outputs": [],
      "source": [
        "do_detected_video(model_ckpt, '/content/mp4/floor_water02.mp4', '/content/mp4/floor_water_out_02_epochs_150_batch_64_lr_0.002.mp4', score_threshold=0.6, do_print=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhKqE5Z2mmU5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "mask_rcnn_dev01.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}